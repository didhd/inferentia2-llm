engine=Python
option.entryPoint=djl_python.transformers_neuronx
option.model_id=/opt/ml/model/llama3
option.n_positions=8192
option.rolling_batch=vllm
option.neuron_optimize_level=1
option.max_rolling_batch_size=16
option.tensor_parallel_degree=8
option.dtype=fp16
option.enable_mixed_precision_accumulation=true
option.load_split_model=false
option.fuse_qkv=true
option.attention_layout=BSH
option.load_in_8bit=true
option.group_query_attention=replicated-heads

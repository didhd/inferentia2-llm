{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74156eb6-9517-475f-984e-2e76d24fb281",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 실시간 엔드포인트를 Transformers NeuronX 백엔드 엔진과 torchserve를 이용해 호스팅\n",
    "이번 노트북에서는 2-1에서 컴파일된 NEFF 형태의 모델 웨이트를 사용하여 [TorchServe](https://pytorch.org/serve/)와 Neuron을 EC2 Inf2 및 Trn1 인스턴스에서 사용하는 방법을 보여줍니다. \n",
    "\n",
    "이 노트북을 통해 EC2 Inf2/Trn1 인스턴스에서 지원하는 모델을 TorchServe로 서빙하는 방법을 확인할 수 있습니다. 조금 전에 컴파일한 llama3-8b 모델을 사용하여 추론을 해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62083e2-b9dc-4f61-96f2-8a00056d19ce",
   "metadata": {},
   "source": [
    "## TorchServe 코드 확인\n",
    "\n",
    "Jupyter Lab에서 `torchserve_inf.py` 파일을 열고, TorchServe를 이용해 추론할 수 있는 코드를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5e52d-2b6d-4e6e-b645-18c4174a8ff0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat torchserve_inf2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5139614f-ea31-4968-bc87-ea099c8acdcc",
   "metadata": {},
   "source": [
    "`torchserve_config.yaml` 파일을 열고, 설정을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db652d9-5e8d-4f88-ac1e-448145f6ef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat torchserve_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e8fc7a-1608-4fa7-9799-34d4bbdcb09d",
   "metadata": {},
   "source": [
    "## TorchServe로 모델 스트리밍 형태로 서빙하기\n",
    "\n",
    "서버를 시작합니다. 일반적으로는 별도의 콘솔에서 이를 실행하는 것이 좋지만, 이번 데모에서는 출력 결과를 파일로 리디렉션할 해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0130cb68-0892-4584-ab5c-698746af546a",
   "metadata": {},
   "source": [
    "필요한 종속성을 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a842f02a-3e2e-4d57-ab8e-472d9d89ea90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: torch-model-archiver in /opt/aws_neuronx_venv_transformers_neuronx/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: torchserve in /opt/aws_neuronx_venv_transformers_neuronx/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: setuptools in /opt/aws_neuronx_venv_transformers_neuronx/lib/python3.10/site-packages (70.0.0)\n",
      "Requirement already satisfied: enum-compat in /opt/aws_neuronx_venv_transformers_neuronx/lib/python3.10/site-packages (from torch-model-archiver) (0.0.3)\n",
      "Requirement already satisfied: Pillow in /opt/aws_neuronx_venv_transformers_neuronx/lib/python3.10/site-packages (from torchserve) (10.3.0)\n",
      "Requirement already satisfied: psutil in /opt/aws_neuronx_venv_transformers_neuronx/lib/python3.10/site-packages (from torchserve) (5.9.8)\n",
      "Requirement already satisfied: packaging in /opt/aws_neuronx_venv_transformers_neuronx/lib/python3.10/site-packages (from torchserve) (21.3)\n",
      "Requirement already satisfied: wheel in /opt/aws_neuronx_venv_transformers_neuronx/lib/python3.10/site-packages (from torchserve) (0.43.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/aws_neuronx_venv_transformers_neuronx/lib/python3.10/site-packages (from packaging->torchserve) (3.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-model-archiver torchserve setuptools==69.5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d346c8-0366-4d3c-ad13-5e5952d4917e",
   "metadata": {},
   "source": [
    "TorchServe를 실행하기 위해 Java를 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f91b4bb6-89d7-4401-bc4b-759f122401cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://ap-northeast-1.ec2.archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Get:2 http://ap-northeast-1.ec2.archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
      "Hit:3 http://ap-northeast-1.ec2.archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
      "Hit:4 https://download.docker.com/linux/ubuntu jammy InRelease                 \n",
      "Get:5 https://nvidia.github.io/libnvidia-container/stable/ubuntu18.04/amd64  InRelease [1484 B]\n",
      "Get:6 https://apt.corretto.aws stable InRelease [10.7 kB]                      \n",
      "Hit:7 https://nvidia.github.io/nvidia-container-runtime/stable/ubuntu18.04/amd64  InRelease\n",
      "Hit:8 https://nvidia.github.io/nvidia-docker/ubuntu18.04/amd64  InRelease      \n",
      "Get:9 https://apt.corretto.aws stable/main amd64 Packages [17.1 kB]            \n",
      "Hit:10 https://apt.repos.neuron.amazonaws.com jammy InRelease                  \n",
      "Get:11 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
      "Fetched 286 kB in 1s (229 kB/s)     \n",
      "Reading package lists... Done\n",
      "W: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "W: https://nvidia.github.io/libnvidia-container/stable/ubuntu18.04/amd64/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "W: https://nvidia.github.io/nvidia-container-runtime/stable/ubuntu18.04/amd64/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "W: https://nvidia.github.io/nvidia-docker/ubuntu18.04/amd64/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "W: https://apt.repos.neuron.amazonaws.com/dists/jammy/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "Suggested packages:\n",
      "  default-jre\n",
      "The following NEW packages will be installed:\n",
      "  java-common\n",
      "0 upgraded, 1 newly installed, 0 to remove and 24 not upgraded.\n",
      "Need to get 6782 B of archives.\n",
      "After this operation, 37.9 kB of additional disk space will be used.\n",
      "Get:1 http://ap-northeast-1.ec2.archive.ubuntu.com/ubuntu jammy/main amd64 java-common all 0.72build2 [6782 B]\n",
      "Fetched 6782 B in 0s (391 kB/s)       \n",
      "Selecting previously unselected package java-common.\n",
      "(Reading database ... 126988 files and directories currently installed.)\n",
      "Preparing to unpack .../java-common_0.72build2_all.deb ...\n",
      "Unpacking java-common (0.72build2) ...\n",
      "Setting up java-common (0.72build2) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Scanning processes...                                                           \n",
      "Scanning linux images...                                                        \n",
      "\n",
      "Running kernel seems to be up-to-date.\n",
      "\n",
      "No services need to be restarted.\n",
      "\n",
      "No containers need to be restarted.\n",
      "\n",
      "No user sessions are running outdated binaries.\n",
      "\n",
      "No VM guests are running outdated hypervisor (qemu) binaries on this host.\n",
      "--2024-06-22 09:29:00--  https://corretto.aws/downloads/latest/amazon-corretto-17-x64-linux-jdk.deb\n",
      "Resolving corretto.aws (corretto.aws)... 3.165.21.93, 3.165.21.76, 3.165.21.23, ...\n",
      "Connecting to corretto.aws (corretto.aws)|3.165.21.93|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: /downloads/resources/17.0.11.9.1/java-17-amazon-corretto-jdk_17.0.11.9-1_amd64.deb [following]\n",
      "--2024-06-22 09:29:02--  https://corretto.aws/downloads/resources/17.0.11.9.1/java-17-amazon-corretto-jdk_17.0.11.9-1_amd64.deb\n",
      "Reusing existing connection to corretto.aws:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 193962504 (185M) [binary/octet-stream]\n",
      "Saving to: ‘amazon-corretto-17-x64-linux-jdk.deb’\n",
      "\n",
      "amazon-corretto-17- 100%[===================>] 184.98M  26.1MB/s    in 7.5s    \n",
      "\n",
      "2024-06-22 09:29:11 (24.5 MB/s) - ‘amazon-corretto-17-x64-linux-jdk.deb’ saved [193962504/193962504]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get update && sudo apt-get install java-common\n",
    "!wget https://corretto.aws/downloads/latest/amazon-corretto-17-x64-linux-jdk.deb\n",
    "!sudo dpkg --install amazon-corretto-17-x64-linux-jdk.deb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dd95e6-4627-4152-a522-95a82a02cd19",
   "metadata": {},
   "source": [
    "컴파일한 모델을 아카이빙 한 후 model_store 디렉토리로 복사하고, 토크나이저와 config도 복사합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "502450fe-e7a5-4148-9554-d3a39480050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "rm -rf model_store\n",
    "mkdir model_store\n",
    "torch-model-archiver --model-name meta-llama-3-8b-neuronx --version 1.0 --handler torchserve_inf2.py -r requirements.txt --config-file torchserve_config.yaml --extra-files \"meta-llama/Meta-Llama-3-8B/config.json,meta-llama/Meta-Llama-3-8B/generation_config.json,meta-llama/Meta-Llama-3-8B/model-00001-of-00004.safetensors,meta-llama/Meta-Llama-3-8B/model-00002-of-00004.safetensors,meta-llama/Meta-Llama-3-8B/model-00003-of-00004.safetensors,meta-llama/Meta-Llama-3-8B/model-00004-of-00004.safetensors,meta-llama/Meta-Llama-3-8B/model.safetensors.index.json,meta-llama/Meta-Llama-3-8B/special_tokens_map.json,meta-llama/Meta-Llama-3-8B/tokenizer.json,meta-llama/Meta-Llama-3-8B/tokenizer_config.json,torchserve_inf2.py\" --archive-format no-archive\n",
    "mv meta-llama-3-8b-neuronx model_store/\n",
    "cp -r neuron_artifacts model_store/meta-llama-3-8b-neuronx/\n",
    "mv model_store/meta-llama-3-8b-neuronx/neuron_artifacts model_store/meta-llama-3-8b-neuronx/neuron_cache "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df241f7-f8f3-4057-9c97-b8898371363d",
   "metadata": {},
   "source": [
    "## TorchServe 모델 서빙\n",
    "다음으로, 앞서 정의한 모델 설정을 사용하여 컨테이너 엔드포인트를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ece310d1-3922-433d-a21d-9de242e29c57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!export TS_INSTALL_PY_DEP_PER_MODEL=\"true\"\n",
    "!torchserve --ncs --start --model-store model_store --models meta-llama-3-8b-neuronx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a61a226-3178-45a6-a2fb-9f7bec510370",
   "metadata": {},
   "source": [
    "## 추론 테스트\n",
    "TorchServe 엔드포인트가 생성된 후, 엔드포인트에 대해 실시간 스트리밍 예측을 수행할 수 있습니다.\n",
    "- 추론 요청을 제출하고 응답을 받기 위해 아래 Python 코드를 사용합니다.\n",
    "\n",
    "모델 서버에 추론 요청을 제출하고 추론 결과를 받아봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb6cac86-9b46-4d78-a914-2d0c82f58ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks are completed\n",
      "payload={'prompt': 'Today the weather is really nice and I am planning on ', 'max_new_tokens': 50}\n",
      ", output=Today the weather is really nice and I am planning on 2 hours of walking. I am going to walk to the park and then to the beach. I am going to walk to the park and then to the beach. I am going to walk to the park and then to the beach. I am going\n",
      "\n",
      "payload={'prompt': 'Today the weather is really nice and I am planning on ', 'max_new_tokens': 50}\n",
      ", output=Today the weather is really nice and I am planning on 2 hours of walking. I am going to walk to the park and then to the beach. I am going to walk to the park and then to the beach. I am going to walk to the park and then to the beach. I am going\n",
      "\n",
      "payload={'prompt': 'Today the weather is really nice and I am planning on ', 'max_new_tokens': 50}\n",
      ", output=Today the weather is really nice and I am planning on 2 hours of walking. I am going to walk to the park and then to the beach. I am going to walk to the park and then to the beach. I am going to walk to the park and then to the beach. I am going\n",
      "\n",
      "payload={'prompt': 'Today the weather is really nice and I am planning on ', 'max_new_tokens': 50}\n",
      ", output=Today the weather is really nice and I am planning on 2 hours of walking. I am going to walk to the park and then to the beach. I am going to walk to the park and then to the beach. I am going to walk to the park and then to the beach. I am going\n",
      "\n",
      "payload={'prompt': 'Today the weather is really nice and I am planning on ', 'max_new_tokens': 50}\n",
      ", output=Today the weather is really nice and I am planning on 2 hours of walking. I am going to walk to the park and then to the beach. I am going to walk to the park and then to the beach. I am going to walk to the park and then to the beach. I am going\n",
      "\n",
      "payload={'prompt': 'Today the weather is really nice and I am planning on ', 'max_new_tokens': 50}\n",
      ", output=Today the weather is really nice and I am planning on 2 hours of walking. I am going to walk to the park and then to the beach. I am going to walk to the park and then to the beach. I am going to walk to the park and then to the beach. I am going\n",
      "\n",
      "payload={'prompt': 'Today the weather is really nice and I am planning on ', 'max_new_tokens': 50}\n",
      ", output=Today the weather is really nice and I am planning on 2 hours of walking. I am going to walk to the park and then to the beach. I am going to walk to the park and then to the beach. I am going to walk to the park and then to the beach. I am going\n",
      "\n",
      "payload={'prompt': 'Today the weather is really nice and I am planning on ', 'max_new_tokens': 50}\n",
      ", output=Today the weather is really nice and I am planning on 2 hours of walking. I am going to walk to the park and then to the beach. I am going to walk to the park and then to the beach. I am going to walk to the park and then to the beach. I am going\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run single inference request\n",
    "!python utils/llm_streaming.py -m meta-llama-3-8b-neuronx -o 50 -t 2 -n 4 --prompt-text \"Today the weather is really nice and I am planning on \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5539eb3-d631-4b31-b9ed-7a20cd19f2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "payload={'prompt': 'Today the weather is really nice and I am planning on ', 'max_new_tokens': 64}\n",
      ", output=\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/inferentia2-llm/utils/llm_streaming.py\", line 174, in <module>\n",
      "    main()\n",
      "  File \"/home/ubuntu/inferentia2-llm/utils/llm_streaming.py\", line 165, in main\n",
      "    predictor.join()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Run single inference request (Stream)\n",
    "!python utils/llm_streaming.py -m meta-llama-3-8b-neuronx --demo-streaming --prompt-text \"Today the weather is really nice and I am planning on \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d91726-04d8-4534-b0ff-b79c834641ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST \"http://localhost:8080/predictions/meta-llama-3-8b-neuronx\" -H \"Content-Type: application/json\" -d '{\"inputs\": \"Today the weather is really nice and I am planning on\", \"parameters\": {\"max_new_tokens\": 50, \"prompt_randomize\": false}}'"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
